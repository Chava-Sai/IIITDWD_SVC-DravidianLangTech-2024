{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Run 3"
      ],
      "metadata": {
        "id": "j96WopNkj03s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install transformers\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "# Load the dataset from your .xlsx file\n",
        "input_file = \"dravidian_final.xlsx\"\n",
        "df = pd.read_excel(input_file)\n",
        "\n",
        "# Specify the column name containing the text\n",
        "column_to_process = \"english\"\n",
        "text_data = df[column_to_process]\n",
        "\n",
        "# Load hate speech detection tokenizer and model (use HateBERT)\n",
        "tokenizer_hate = AutoTokenizer.from_pretrained(\"GroNLP/hateBERT\")\n",
        "model_hate = AutoModel.from_pretrained(\"GroNLP/hateBERT\")\n",
        "\n",
        "# Define a function to extract embeddings\n",
        "def get_sentence_embeddings(text):\n",
        "    # Tokenize the text\n",
        "    tokens = tokenizer_hate(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    # Forward pass through the model\n",
        "    with torch.no_grad():\n",
        "        output = model_hate(**tokens)\n",
        "    # Extract the embeddings from the output\n",
        "    embeddings = output.last_hidden_state.mean(dim=1)  # You can use other pooling strategies as well\n",
        "    return embeddings\n",
        "\n",
        "# Calculate embeddings for the text data\n",
        "embeddings_list = []\n",
        "for text in text_data:\n",
        "    embeddings = get_sentence_embeddings(text)\n",
        "    embeddings_list.append(embeddings)\n",
        "\n",
        "# Convert the list of embeddings to a single tensor\n",
        "all_embeddings = torch.cat(embeddings_list)\n",
        "\n",
        "# Save the embeddings as a PyTorch tensor\n",
        "torch.save(all_embeddings, \"hate_embeddings_hatebert.pt\")\n",
        "\n",
        "print(\"Embeddings saved as hate_embeddings_hatebert.pt\")\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset from your .xlsx file\n",
        "input_file = \"dravidian_final.xlsx\"  # Replace with your file path\n",
        "df = pd.read_excel(input_file)\n",
        "label_mapping = {\"hate\": 1, \"non-hate\": 0}\n",
        "\n",
        "# Map the labels using the mapping\n",
        "df['Label'] = df['Label'].map(label_mapping)\n",
        "\n",
        "# Load embeddings from \"embeddings.pt\"\n",
        "all_embeddings = torch.load(\"hate_embeddings_hatebert.pt\")\n",
        "\n",
        "# Prepare the labels\n",
        "labels_hate = torch.tensor(df['Label'].values)\n",
        "\n",
        "# Split the data into train and test sets\n",
        "# train_embeddings, test_embeddings, train_labels_hate, test_labels_hate = train_test_split(all_embeddings, labels_hate, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset from your .xlsx file\n",
        "input_file = \"dravidian_final.xlsx\"  # Replace with your file path\n",
        "df = pd.read_excel(input_file)\n",
        "\n",
        "# Load embeddings from \"embeddings.pt\"\n",
        "all_embeddings = torch.load(\"hate_embeddings_hatebert.pt\")\n",
        "label_mapping = {\"hate\": 1, \"non-hate\": 0}\n",
        "\n",
        "# Map the labels using the mapping\n",
        "df['Label'] = df['Label'].map(label_mapping)\n",
        "\n",
        "# Prepare the labels for hate detection\n",
        "labels_hate = torch.tensor(df['Label'].values)\n",
        "\n",
        "# Split the data into train and test sets\n",
        "train_embeddings, test_embeddings, train_labels_hate, test_labels_hate = train_test_split(all_embeddings, labels_hate, test_size=0.1, random_state=42)\n",
        "\n",
        "# Define a custom dataset for hate detection\n",
        "class HateDetectionDataset(Dataset):\n",
        "    def __init__(self, embeddings, labels_hate):\n",
        "        self.embeddings = embeddings\n",
        "        self.labels_hate = labels_hate\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.embeddings)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.embeddings[idx], self.labels_hate[idx]\n",
        "\n",
        "# Create data loaders for training and testing\n",
        "batch_size = 32  # Set your batch size\n",
        "train_dataset = HateDetectionDataset(train_embeddings, train_labels_hate)\n",
        "test_dataset = HateDetectionDataset(test_embeddings, test_labels_hate)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "# Define the hate detection model\n",
        "class HateDetectionModel(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.hate_classifier = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, embeddings):\n",
        "        hate_logits = self.hate_classifier(embeddings)\n",
        "        return hate_logits\n",
        "\n",
        "# Initialize and train the hate detection model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = HateDetectionModel(all_embeddings.shape[1])\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "num_epochs = 9  # Set the number of training epochs\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for batch in train_loader:\n",
        "        embeddings, labels_hate = [x.to(device) for x in batch]\n",
        "\n",
        "        hate_logits = model(embeddings)\n",
        "\n",
        "        loss_hate = criterion(hate_logits.view(-1), labels_hate.float())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss_hate.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Save the model if needed\n",
        "torch.save(model.state_dict(), \"hate_detection_model_hbert.h5\")\n",
        "print(\"Trained model saved to hate_detection_model.h5\")\n",
        "\n",
        "\n",
        "# New cell for classification report\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # Calculate metrics for hate detection\n",
        "    hate_preds = []\n",
        "    for batch in test_loader:\n",
        "        embeddings, _ = [x.to(device) for x in batch]\n",
        "\n",
        "        hate_logits = model(embeddings)\n",
        "        hate_preds.extend(torch.sigmoid(hate_logits).cpu().numpy())\n",
        "\n",
        "# Generate classification report\n",
        "from sklearn.metrics import classification_report\n",
        "class_names = [\"non-hate\", \"hate\"]\n",
        "\n",
        "classification_rep = classification_report(\n",
        "    np.array(test_labels_hate),\n",
        "    (np.array(hate_preds) >= 0.5).astype(int),\n",
        "    target_names=class_names,\n",
        ")\n",
        "print(\"Classification Report for Hate Detection hateBERT :\")\n",
        "print(classification_rep)\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "# Load the new dataset from the separate .xlsx file\n",
        "new_input_file = \"dravidian_test.xlsx\"\n",
        "new_df = pd.read_excel(new_input_file)\n",
        "\n",
        "# Assuming you have a column named \"Text\" in the new dataset\n",
        "new_text_data = new_df[\"english\"]\n",
        "\n",
        "# Load BERT tokenizer and model for embeddings\n",
        "tokenizer_hate = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Tokenize and obtain embeddings for the new text dataz\n",
        "new_embeddings_list = []\n",
        "\n",
        "for text in new_text_data:\n",
        "    tokens = tokenizer_hate(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        output = model_hate(**tokens)\n",
        "    embeddings = output.last_hidden_state.mean(dim=1)\n",
        "    new_embeddings_list.append(embeddings)\n",
        "\n",
        "new_embeddings = torch.cat(new_embeddings_list)\n",
        "\n",
        "# Create a dataset and loader for the new data\n",
        "new_dataset = HateDetectionDataset(new_embeddings, torch.zeros(len(new_embeddings)))  # Labels are not used for prediction\n",
        "new_loader = DataLoader(new_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Load the saved model\n",
        "loaded_model = HateDetectionModel(all_embeddings.shape[1])\n",
        "loaded_model.load_state_dict(torch.load(\"hate_detection_model.h5\"))\n",
        "loaded_model.to(device)\n",
        "loaded_model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Make predictions on the new data\n",
        "with torch.no_grad():\n",
        "    new_predictions = []\n",
        "\n",
        "    for batch in new_loader:\n",
        "        embeddings, _ = [x.to(device) for x in batch]\n",
        "\n",
        "        hate_logits = loaded_model(embeddings)\n",
        "        hate_probs = torch.sigmoid(hate_logits).cpu().numpy()\n",
        "\n",
        "        # Convert probabilities to binary predictions (0 or 1)\n",
        "        hate_preds = (hate_probs >= 0.5).astype(int)\n",
        "\n",
        "        new_predictions.extend(hate_preds)\n",
        "\n",
        "# Flatten the arrays in new_predictions\n",
        "new_predictions_flat = [item for sublist in new_predictions for item in sublist]\n",
        "\n",
        "# Map the array values to \"hate\" and \"not-hate\"\n",
        "prediction_mapping = {1: \"hate\", 0: \"not-hate\"}\n",
        "new_df['Predictions'] = new_predictions_flat\n",
        "new_df['Predictions'] = new_df['Predictions'].map(prediction_mapping)\n",
        "\n",
        "# Save the dataframe to an Excel file\n",
        "output_file = \"drav_out_bertuc.xlsx\"\n",
        "new_df.to_excel(output_file, index=False)\n",
        "\n",
        "print(f\"Predictions saved to {output_file}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "CFbRHqORjxa7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}