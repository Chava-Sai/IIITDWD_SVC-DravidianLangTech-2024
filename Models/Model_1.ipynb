{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Run 1"
      ],
      "metadata": {
        "id": "VBnd9q3jjqmh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "# Load the dataset from your .xlsx file\n",
        "input_file = \"dravidian_final.xlsx\"\n",
        "df = pd.read_excel(input_file)\n",
        "\n",
        "# Specify the column name containing the text\n",
        "column_to_process = \"english\"\n",
        "text_data = df[column_to_process]\n",
        "\n",
        "# Load hate speech detection tokenizer and model (use XLM-RoBERTa)\n",
        "tokenizer_hate = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
        "model_hate = AutoModel.from_pretrained(\"xlm-roberta-base\")\n",
        "\n",
        "\n",
        "# Define a function to extract embeddings\n",
        "def get_sentence_embeddings(text):\n",
        "  # Tokenize the text\n",
        "  tokens = tokenizer_hate(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "  # Forward pass through the model\n",
        "  with torch.no_grad():\n",
        "      output = model_hate(**tokens)\n",
        "  # Extract the embeddings from the output\n",
        "  embeddings = output.last_hidden_state.mean(dim=1) # You can use other pooling strategies as well\n",
        "  return embeddings\n",
        "\n",
        "# Calculate embeddings for the text data\n",
        "embeddings_list = []\n",
        "for text in text_data:\n",
        "  embeddings = get_sentence_embeddings(text)\n",
        "  embeddings_list.append(embeddings)\n",
        "\n",
        "# Convert the list of embeddings to a single tensor\n",
        "all_embeddings = torch.cat(embeddings_list)\n",
        "\n",
        "# Save the embeddings as a PyTorch tensor\n",
        "torch.save(all_embeddings, \"hate_embeddings_xlmroberta.pt\")\n",
        "\n",
        "print(\"Embeddings saved as hate_embeddings_xlmroberta.pt\")\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset from your .xlsx file\n",
        "input_file = \"dravidian_final.xlsx\"  # Replace with your file path\n",
        "df = pd.read_excel(input_file)\n",
        "label_mapping = {\"hate\": 1, \"non-hate\": 0}\n",
        "\n",
        "# Map the labels using the mapping\n",
        "df['Label'] = df['Label'].map(label_mapping)\n",
        "\n",
        "# Load embeddings from \"embeddings.pt\"\n",
        "all_embeddings = torch.load(\"hate_embeddings_xlmroberta.pt\")\n",
        "\n",
        "# Prepare the labels\n",
        "labels_hate = torch.tensor(df['Label'].values)\n",
        "\n",
        "# Split the data into train and test sets\n",
        "# train_embeddings, test_embeddings, train_labels_hate, test_labels_hate = train_test_split(all_embeddings, labels_hate, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset from your .xlsx file\n",
        "input_file = \"dravidian_final.xlsx\"  # Replace with your file path\n",
        "df = pd.read_excel(input_file)\n",
        "\n",
        "# Load embeddings from \"embeddings.pt\"\n",
        "all_embeddings = torch.load(\"hate_embeddings_xlmroberta.pt\")\n",
        "label_mapping = {\"hate\": 1, \"non-hate\": 0}\n",
        "\n",
        "# Map the labels using the mapping\n",
        "df['Label'] = df['Label'].map(label_mapping)\n",
        "\n",
        "# Prepare the labels for hate detection\n",
        "labels_hate = torch.tensor(df['Label'].values)\n",
        "\n",
        "# Split the data into train and test sets\n",
        "train_embeddings, test_embeddings, train_labels_hate, test_labels_hate = train_test_split(all_embeddings, labels_hate, test_size=0., random_state=42)\n",
        "\n",
        "# Define a custom dataset for hate detection\n",
        "class HateDetectionDataset(Dataset):\n",
        "    def __init__(self, embeddings, labels_hate):\n",
        "        self.embeddings = embeddings\n",
        "        self.labels_hate = labels_hate\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.embeddings)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.embeddings[idx], self.labels_hate[idx]\n",
        "\n",
        "# Create data loaders for training and testing\n",
        "batch_size = 32  # Set your batch size\n",
        "train_dataset = HateDetectionDataset(train_embeddings, train_labels_hate)\n",
        "test_dataset = HateDetectionDataset(test_embeddings, test_labels_hate)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "# Define the hate detection model\n",
        "class HateDetectionModel(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.hate_classifier = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, embeddings):\n",
        "        hate_logits = self.hate_classifier(embeddings)\n",
        "        return hate_logits\n",
        "\n",
        "# Initialize and train the hate detection model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = HateDetectionModel(all_embeddings.shape[1])\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "num_epochs = 9  # Set the number of training epochs\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for batch in train_loader:\n",
        "        embeddings, labels_hate = [x.to(device) for x in batch]\n",
        "\n",
        "        hate_logits = model(embeddings)\n",
        "\n",
        "        loss_hate = criterion(hate_logits.view(-1), labels_hate.float())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss_hate.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Save the model if needed\n",
        "torch.save(model.state_dict(), \"hate_detection_model_xlm.h5\")\n",
        "print(\"Trained model saved to hate_detection_model.h5\")\n",
        "\n",
        "\n",
        "# New cell for classification report\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # Calculate metrics for hate detection\n",
        "    hate_preds = []\n",
        "    for batch in test_loader:\n",
        "        embeddings, _ = [x.to(device) for x in batch]\n",
        "\n",
        "        hate_logits = model(embeddings)\n",
        "        hate_preds.extend(torch.sigmoid(hate_logits).cpu().numpy())\n",
        "\n",
        "# Generate classification report\n",
        "from sklearn.metrics import classification_report\n",
        "class_names = [\"non-hate\", \"hate\"]\n",
        "\n",
        "classification_rep = classification_report(\n",
        "    np.array(test_labels_hate),\n",
        "    (np.array(hate_preds) >= 0.5).astype(int),\n",
        "    target_names=class_names,\n",
        ")\n",
        "print(\"Classification Report for Hate Detection Xlm-RoBERTa :\")\n",
        "print(classification_rep)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CfWi67fDjm-X"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}